{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20467be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet langchain langchain-community langchain-groq neo4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"neo4j://127.0.0.1:7687\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"gihanlakmal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NEO4J_URI\"]=NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"]=NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"]=NEO4J_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106aacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "raw_document = WikipediaLoader(query=\"Elizabath queen\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810118a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=\"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\",\n",
    "    model=\"deepseek-r1-distill-llama-70b\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9d52894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the first 6 documents: 15528\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(6):\n",
    "    total += len(raw_document[i].page_content)\n",
    "print(f\"Total number of characters in the first 6 documents: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(raw_document[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c739a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f882061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aab235",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee009929",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents , baseEntityLabel=True , include_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_query = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s , r , t LIMIT 50\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_graph(cypher: str):\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    session = driver.session()\n",
    "\n",
    "    result = session.run(cypher)\n",
    "\n",
    "    net = Network(notebook=True, height=\"600px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "    nodes = set()\n",
    "    edges = []\n",
    "\n",
    "    for record in result:\n",
    "        for key in record.keys():\n",
    "            value = record[key]\n",
    "            # Handle Nodes\n",
    "            if hasattr(value, 'element_id') and hasattr(value, 'labels'):\n",
    "                node_id = str(value.element_id)\n",
    "                if node_id not in nodes:\n",
    "                    label = value.get(\"name\") or value.get(\"title\") or f\"Node {node_id}\"\n",
    "                    net.add_node(node_id, label=label)\n",
    "                    nodes.add(node_id)\n",
    "            # Handle Relationships\n",
    "            elif hasattr(value, 'start_node') and hasattr(value, 'end_node'):\n",
    "                start_id = str(value.start_node.element_id)\n",
    "                end_id = str(value.end_node.element_id)\n",
    "                rel_type = value.type\n",
    "                edges.append((start_id, end_id, rel_type))\n",
    "\n",
    "    # Add edges\n",
    "    for start_id, end_id, rel_type in edges:\n",
    "        if start_id in nodes and end_id in nodes:\n",
    "            net.add_edge(start_id, end_id, label=rel_type)\n",
    "\n",
    "    session.close()\n",
    "\n",
    "    net.show(\"graph.html\")\n",
    "    display(HTML(\"graph.html\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c93048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(default_query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"graph.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f62196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ff4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46acdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple , List , Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ea31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embedding=embedding,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Extract entities from text\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "    \n",
    "    names: List[str] = Field(\n",
    "            ...,\n",
    "            description=\"All the person, organization, or business entities that \"\n",
    "            \"appear in the text\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaeb57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt  = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        \n",
    "        (\"system\", \"You are extracting organization and person entities from the text.\"),\n",
    "        (\"human\", \"Use the given format to extract information from the following \"  \"input: {question}\" ),\n",
    "        \n",
    "    ]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f2c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_chain = prompt | llm.with_structured_output( Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc7ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_chain.invoke({\"question\": \"Who is the Elizabath?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_text_query(input: str) -> str:\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\"{word}~2 AND\"\n",
    "    full_text_query += f\"{words[-1]}~2\"\n",
    "    return full_text_query.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "672e881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_retriever(question: str) -> list[str]:\n",
    "    # Step 1: Extract entities\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "\n",
    "    # Step 2: Initialize result string\n",
    "    results = \"\"\n",
    "\n",
    "    # Step 3: Query Neo4j for each entity\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"\n",
    "            CALL db.index.fulltext.queryNodes('keyword', $query, {limit: 2})\n",
    "            YIELD node, score\n",
    "            CALL {\n",
    "                WITH node\n",
    "                MATCH (node)-[r:MENTIONS]->(neighbor)\n",
    "                RETURN node.id + ' -[' + type(r) + ']-> ' + neighbor.id AS output\n",
    "                UNION\n",
    "                MATCH (node)<-[r:MENTIONS]-(neighbor)\n",
    "                RETURN neighbor.id + ' -[' + type(r) + ']-> ' + node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        results += \"\\n\".join([el[\"output\"] for el in response])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a56a662e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Queen Elizabeth Hospital\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> King'S Lynn\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Norfolk\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> England\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> West Norfolk\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> South Lincolnshire\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Fenland District\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Cambridgeshire\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Queen Elizabeth Hospital King'S Lynn Nhs Foundation Trust\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Queen Elizabeth The Queen Mother\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Reinforced Autoclaved Aerated Concrete Plank Roof\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Fermoy Unit\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Sandringham\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Arthur Levin Day Surgery Centre\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Queen Elizabeth Ii\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Macmillan Cancer Unit\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Princess Anne\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Critical Care Unit\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Roxburgh Children'S Day Centre\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Raac Plank Roof\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 1980\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2020\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2021\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Queen Elizabeth Hospital, King'S Lynn\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Fenland District, Cambridgeshire\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> King Edward Vii'S Hospital, London\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Windsor Castle\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Reinforced Autoclaved Aerated Concrete (Raac)\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> The Guardian\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2020 Proposal To Rebuild Queen Elizabeth Hospital\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> King Edward Vii'S Hospital In London\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 1998\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 1999\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2002\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2003\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2005\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2008\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2011\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> 2023\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Northern Fenland District\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Golden Jubilee\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Foundation Trust Status\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Reinforced Autoclaved Aerated Concrete\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> London\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Northern Fenland District, Cambridgeshire\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Structural Issues With Raac Plank Roof\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Installation Of Support Props\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Evacuation And Closure Of Critical Care Unit\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> Rebuilding Of Queen Elizabeth Hospital\n",
      "63edb6a89cb9d7a07b7f9db5d26ee613 -[MENTIONS]-> King Edward Vii'S Hospital\n"
     ]
    }
   ],
   "source": [
    "print(structured_retriever(\"Who is the Elizabath ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7ade7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(question: str):\n",
    "    print(f\"search query: {question}\")\n",
    "    structured_data= structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "{structured_data}\n",
    "Unstructured data:\n",
    "{\"Document \".join(unstructured_data)}\n",
    "\"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c4bf3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question , rephrase the follow up question to be a standalone question,\n",
    "in its original langugae .\n",
    "Chat History:\n",
    "{chat_history}Follow Up Input: {question}\n",
    "Rephrased Question:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "06719edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0ad0d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch, RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3d2c2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assume this function is defined somewhere\n",
    "def _format_chat_history(history):\n",
    "    return \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in history])\n",
    "\n",
    "# Example prompt (should be a valid PromptTemplate)\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template) # Your PromptTemplate here\n",
    "\n",
    "_search_query = RunnableBranch(\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | llm \n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    RunnableLambda(lambda x: x[\"question\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "055f27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are an intelligent assistant helping users answer factual questions.\n",
    "\n",
    "Context:|\n",
    "{context}\n",
    "\n",
    "Answer the following question using only the information from the context above.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Write the answer in a **clear, well-structured paragraph**, without listing steps or saying \"let me think.\" Avoid verbose or repeated parts. Keep it informative and natural.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "880cda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query |retriever , \n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    |prompt\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "caab6e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search query: who is the Elizabath  ? \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, I need to figure out who \"Elizabeth\" refers to based on the provided context. Let me go through the information step by step.\\n\\nFirst, looking at the structured data, there are mentions of \"Queen Elizabeth Hospital\" and \"Queen Elizabeth The Queen Mother.\" This suggests that there are two prominent Elizabeths: Queen Elizabeth II and her mother, also named Elizabeth.\\n\\nIn the unstructured text, it\\'s mentioned that the hospital is named after Queen Elizabeth The Queen Mother, not Queen Elizabeth II. This clarifies that there are two different Elizabeths involved. Additionally, the text talks about events involving Queen Elizabeth II, such as her visiting the hospital and opening certain units, which indicates she\\'s a separate individual.\\n\\nThere\\'s also mention of Princess Elizabeth, who later became Queen Elizabeth II, in the context of the cottage Y Bwthyn Bach, which was a gift to her when she was a princess. This further distinguishes between the two Elizabeths: the mother and the daughter.\\n\\nSo, putting it all together, \"Elizabeth\" in this context refers to two key figures: Queen Elizabeth The Queen Mother and her daughter, Queen Elizabeth II. They are both part of the British royal family and have connections to the mentioned hospital and other locations like Windsor Castle.\\n\\nI should structure the answer to clearly differentiate between the two, explaining their roles and how they are mentioned in the context provided.\\n</think>\\n\\nThe context refers to two prominent figures named Elizabeth. Queen Elizabeth The Queen Mother is the namesake of Queen Elizabeth Hospital in King\\'s Lynn, Norfolk, England, rather than Queen Elizabeth II. Queen Elizabeth II is mentioned in various events, such as visiting the hospital and opening facilities like the Macmillan Cancer Unit during her Golden Jubilee. Additionally, Princess Elizabeth, later Queen Elizabeth II, received Y Bwthyn Bach, a cottage, as a gift. Thus, Elizabeth refers to both the mother and daughter in the British royal family, each involved in different contexts within the provided information.'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"question\": \"who is the Elizabath  ? \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0fa42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
